# Copyright (C) 2020 Joris Zimmermann

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program. If not, see https://www.gnu.org/licenses/.

"""Provide post-processing for ground temperatures from TRNSYS storage types.

Type 342
"Multiflow Stratified Storage Model with Full Mixed Storage Layers - XST"

Type 343 "ICEPIT"

Type 1301 'Ground Coupling for a Buried Truncated Cone Storage Tank'

"""
import re
import os
import math
import logging
import pandas as pd
import matplotlib.pyplot as plt  # Plotting library
from io import StringIO
import trnpy.misc  # Miscellaneous helper functions
import imageio
import io
import subprocess

# Define the logging function
logger = logging.getLogger(__name__)


def read_result_342(file, start_date=None, resample_rule=None):
    """Read the result file of TRNSYS XST model (Type 342).

    Reading the file generated by the XST model is a challenge.
    For each time step, a table of temperatures in z and r directions is
    printed. We can use a regular expression to detect those tables
    and to which time step they belong. For large storages, XST will
    print the many columns in tables below each other. Those two halves of
    a single table are referred to as data1 and data2.
    """
    with open(file, 'r') as f:
        content = f.read()

    # The XST out-file is messed up at some points with missing whitespace.
    # Insert a whitespace between a digit and a minus sign:
    content = re.sub(r'(\d)-', r'\1 -', content)
    # Seperate two decimal values:
    content = re.sub(r'(\d+\.\d+)(\d\.\d+)', r'\1 \2', content)
    # Separate two exponential values:
    content = re.sub(r'(\dE-*\d{2})(\d+\.)', r'\1 \2', content)

    # This regular expression finds the data we need
    regex = (r"Time\ \(h\)\ *(?P<time>\S+)\n.*R-DIST\n"
             r"(?P<data1>\s+Z-DIST.*\n\s-+\n(.*\n)+?)"
             r"(.*R-DIST\n(?P<data2>.*\n(.*\n)+?)\s--*?\n|\s--*?\n)")

    # Get a set of matches for each time step
    matches = re.finditer(regex, content, re.MULTILINE)

    time_list = []
    df_list = []

    for match in matches:
        time = float(match.group('time'))
        data1 = match.group('data1')
        data2 = match.group('data2')

        df1 = pd.read_csv(StringIO(data1), sep=r'\s+', header=0,
                          index_col=0, skiprows=[1])
        if data2 is not None:
            df2 = pd.read_csv(StringIO(data2), sep=r'\s+', header=0,
                              index_col=0, skiprows=[1])
        else:
            df2 = pd.DataFrame()
        df = pd.concat([df1, df2], axis=1)

        # The first column (center with radius=0) stays at a constant
        # initial temperature for some reason. Insert the values of the
        # second column instead:
        df[df.columns[0]] = df[df.columns[1]]

        # Break if there are any missing values:
        if df.isnull().values.any():
            print(file)
            print(time)
            print(data1)
            print(data2)
            print(df)
            raise ValueError('Stopping parsing the XST results, because NaN '
                             'values were found in the resulting DataFrame.')

        time_list.append(time)
        df_list.append(df)

    if start_date is not None:
        time_list = (pd.to_datetime(start_date)
                     + pd.to_timedelta(time_list, unit='h'))

    df = pd.concat(df_list, keys=time_list, names=['time'])
    df.columns.set_names('R-DIST', inplace=True)

    if resample_rule is not None:
        df = resample_ground_temperatures(df, rule=resample_rule)

    return df


def read_result_343(file, start_date=None, resample_rule=None):
    """Read the result file of TRNSYS storage type 343 ("ICEPIT").

    In order to make Type 343 create the output file, parameter 86 has
    to be set to any number, e.g. 343. The output file is then created
    by TRNSYS with the name 'fort.343'.
    """
    with open(file, 'r') as f:
        content = f.read()

    # This regular expression finds the data we need
    regex = (r"time = *(?P<time>\S+)\ h\n\n(?P<data>\s+Radius(.*\n)+?)\n")

    # Get a set of matches for each time step
    matches = re.finditer(regex, content, re.MULTILINE)

    time_list = []
    df_list = []

    for match in matches:
        time = float(match.group('time'))
        # if time % 48 != 0:
        #     continue  # skip if not a multiple of 48 hours
        data = match.group('data')

        df = pd.read_csv(StringIO(data), sep=r'\s+', header=0,
                         index_col=0, skiprows=[1])

        # Break if there are any missing values:
        if df.isnull().values.any():
            print(file)
            print(time)
            print(df)
            raise ValueError('Stopping parsing the results, because NaN '
                             'values were found in the resulting DataFrame.')

        df.columns.set_names('R-DIST', inplace=True)
        df.index.set_names('Z-DIST', inplace=True)
        time_list.append(time)
        df_list.append(df)

    if start_date is not None:
        time_list = (pd.to_datetime(start_date)
                     + pd.to_timedelta(time_list, unit='h'))

    df = pd.concat(df_list, keys=time_list, names=['time'])

    if resample_rule is not None:
        df = resample_ground_temperatures(df, rule=resample_rule)

    return df


def read_result_1301(files, freq=1, start_date=None, resample_rule=None,
                     z_new=None, r_new=None, interpolation_method='linear'):
    """Read the result files of TRNSYS type 1301.

    Type 1301: 'Ground Coupling for a Buried Truncated Cone Storage Tank'

    This TRNSYS type prints a new file for each time step. Currently it
    is assumed that there is one file per hour.

    Spatial interpolation onto a new coordinate grid
    can be performed after every file is read (e.g. to save memory)
    """
    time_list = []
    df_list = []
    n_files = len(files)
    for i, file in enumerate(files):
        logger.info("Loading file %s of %s (%.0f%%)", i, n_files,
                    i/n_files*100)
        # Time step is in the file name after the last underscore
        try:
            time = int(file.split('_')[-1]) * freq
        except ValueError:
            # Skip reading this file if the time cannot be determined
            # (The first file 1301 prints is an empty file without time stamp)
            continue
        # Read the step size of radial and vertical cells
        r_steps = pd.read_csv(file, sep=r'\s+', header=None,
                              skiprows=[0], nrows=1)
        z_steps = pd.read_csv(file, sep=r'\s+', header=None,
                              skiprows=[0, 1], nrows=1)
        # Use cumulative sum to get the distances
        r_dist = r_steps.T.cumsum()
        z_dist = z_steps.T.cumsum()

        # Read the actual temperature data
        df = pd.read_csv(file, sep=r'\s+', header=None, skiprows=[0, 1, 2])
        df.columns = r_dist[0]
        df.columns.set_names('R-DIST', inplace=True)

        df['Z-DIST'] = z_dist
        df = df.set_index('Z-DIST')

        # Optionally perform spatial interpolation onto a new coordinate grid
        if z_new is not None and r_new is not None:
            df = interpolate_to_fixed_grid(
                df, z_new, r_new, method=interpolation_method)

        time_list.append(time)
        df_list.append(df)

    if start_date is not None:
        time_list = (pd.to_datetime(start_date)
                     + pd.to_timedelta(time_list, unit='h'))

    df = pd.concat(df_list, keys=time_list, names=['time'])
    df.sort_index(inplace=True)

    if resample_rule is not None:
        # Resample the time index
        df = resample_ground_temperatures(df, rule=resample_rule)

    return df


def resample_ground_temperatures(df, rule):
    """Resample mean temperatures in df with given rule, e.g. '24h'."""
    df_resample = (df
                   .unstack(level='Z-DIST')
                   .resample(rule=rule, level='time')
                   .mean()
                   .stack(level='Z-DIST')
                   )
    return df_resample


def plot_ground_temperatures(df, time_select=[], plot_show=False):
    """Plot ground temperature results of TRNSYS storage types."""
    # Plot for each time step
    T_min = min(-10, math.floor(df.values.min()))
    T_max = max(50, math.ceil(df.values.max()))
    n_levels = list(range(T_min, T_max+4, 5))  # For colorbar
    n_levels = list(range(T_min, T_max+4, 1))  # For colorbar

    logger.debug('Ground temperature min: {}°C max: {}°C'.format(T_min, T_max))

    if not time_select:
        time_select = df.index.get_level_values('time').unique()

    return_dict = dict()
    for time in time_select:
        df_step = df.xs(time, level='time')
        df_temp = df_step.unstack().reset_index()
        df_temp.rename(columns={0: 'Temp'}, inplace=True)
        x = df_temp['R-DIST']
        y = df_temp['Z-DIST'] * (-1)
        z = df_temp['Temp']
        title = 'Zeit: {}'.format(time)

        fig = plot_contour(x, y, z, x_label='Radius [m]', y_label='Tiefe [m]',
                           title=title, n_levels=n_levels)
        return_dict[time] = fig

        if plot_show:
            plt.show()

    return return_dict


def plot_contour(x, y, z, x_label='', y_label='', title='', cmap="cool",
                 n_levels=14):
    """Create contour plot with matplotlib."""
    fig = plt.figure(figsize=(8, 5.1))  # try 1:1 ratio for both axis
    ax = fig.gca()
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    CS = ax.tricontour(x, y, z, levels=n_levels, linewidths=0.1, colors='k')

    plt.clabel(CS, fontsize=7, inline=True, fmt='%1.0f',
               # manual=True,
               )

    cntr = ax.tricontourf(x, y, z, levels=n_levels, cmap=cmap)
    fig.colorbar(cntr, ax=ax, label='Temperatur [°C]', format='%.0f',)
    ax.set_title(title)
    # ax.set_xlim(0, 120)
    # ax.set_ylim(-100, 0)
    # ax.set_xlim(0, 120)
    # ax.set_ylim(-100, 0)
    return fig


def interpolate_to_fixed_grid(df, z_new, r_new, method='linear'):
    """Perform 2D-interpolation to z_new and r_new for all time steps in df.

    Parameters
    ----------
    df : DataFrame
        DataFrame with columns 'R-DIST' and rows 'Z-DIST' for radial
        and vertical distance. The index may optionally also have a level
        'time', then the interpolation is performed for each time step.
    z_new : list
        List of new vertical coordinates below the surface.
    r_new : list
        List of new horizontal radial coordinates.
    method : {'linear', 'nearest', 'cubic'}, optional
        One of the available interpolation methods of
        scipy.interpolate.griddata. The default is 'linear'.

    Returns
    -------
    df_new : DataFrame
        The spatially interpolated DataFrame.

    """
    import itertools
    from scipy.interpolate import griddata

    combis = [items for items in itertools.product(z_new, r_new)]
    idx_new = pd.MultiIndex.from_frame(
        pd.DataFrame(combis),
        names=['Z-DIST', 'R-DIST'])
    xi = idx_new.to_frame().to_numpy()

    if 'time' in df.index.names:
        cols = []
        for time in df.index.get_level_values('time').unique():
            df_step = df.xs(time, level='time')

            df_step = df_step.stack()
            points = df_step.index.to_frame().to_numpy()
            values = df_step.to_numpy()

            df_new = pd.DataFrame(index=idx_new)
            df_new[time] = griddata(points, values, xi, method=method)
            cols.append(df_new)

        df_new = pd.concat(cols, axis='columns')
        df_new = df_new.T.stack('Z-DIST')
        df_new.index.set_names('time', level=0, inplace=True)

    else:
        df_step = df.stack()
        points = df_step.index.to_frame().to_numpy()
        values = df_step.to_numpy()

        df_new = pd.Series(
            index=idx_new,
            data=griddata(points, values, xi, method=method),
            )
        df_new = df_new.unstack('Z-DIST').T

    return df_new


def plot_from_trnpy_dck_list(dck_list, origin, folder, only_Tmax=True,
                             save_ext=['png'], save_GIF=False,
                             slice_time=None, type_=342):
    """Plot storage temperature from results with the TRNpy module."""
    df = collect_from_trnpy_dck_list(dck_list, origin, type_=type_)

    hash_list = df.index.get_level_values('hash').unique()
    for hash_ in hash_list:
        df_hash = df.xs(hash_, level='hash')

        # If the hashes were simulated with different storage diameters,
        # the R-DIST columns will not match for each hash. Remove NaN columns:
        df_hash.dropna(axis='columns', how='all', inplace=True)

        if slice_time is not None:
            start = pd.Timestamp(slice_time[0])
            end = pd.Timestamp(slice_time[1])
            df_hash = df_hash.loc[start:end]

        if df_hash.empty:
            logger.error("After slicing from {start} to {end}, DataFrame "
                         "with ground temperatures from hash {hash_} is "
                         "emtpy. This may be caused by an unsuccessful "
                         "simulation. Skipping..."
                         .format(start=start, end=end, hash_=hash_))
            continue

        time_select = df_hash.index.get_level_values('time').unique()
        if only_Tmax:  # Find the time step with maximum temperature
            time_Tmax = df_hash.unstack().max(axis=1).idxmax()
            time_select = [time_Tmax]

        if save_GIF:  # Create the writer file object only if needed for GIF
            file_gif = os.path.join(
                folder, 'Type {} Erdreich #{}.gif'.format(type_, hash_))
            if not os.path.exists(os.path.dirname(file_gif)):
                os.makedirs(os.path.dirname(file_gif))
            writer = imageio.get_writer(file_gif, mode='I')

        logger.info('Creating and saving XST ground temperature plots '
                    'for #{}'.format(hash_))
        for i, time in enumerate(time_select, start=1):
            # Print progress
            print('\r#{}: Figure {:3d}/{}'.format(hash_, i, len(time_select)),
                  end='\r')
            # Plot and save each time step separately
            fig_dict = plot_ground_temperatures(df_hash, time_select=[time])
            for time, fig in fig_dict.items():
                for ext in save_ext:
                    filename = 'Type {} Erdreich #{} {}.{}'.format(
                        type_, hash_, time.strftime('%Y-%m-%d_%H-%M-%S'), ext)
                    path = os.path.join(folder, str(hash_), filename)
                    if not os.path.exists(os.path.dirname(path)):
                        os.makedirs(os.path.dirname(path))

                    if ext == 'emf':
                        subprocess.run([
                            r"C:\Program Files\Inkscape\bin\inkscape.exe",
                            os.path.splitext(path)[0]+'.svg',
                            "--export-filename",
                            path])
                    else:
                        # Regular file save:
                        fig.savefig(path, dpi=500, bbox_inches='tight')

                if save_GIF:  # GIF save:
                    buffer = io.BytesIO()
                    fig.savefig(buffer, dpi=150, bbox_inches='tight')
                    plt.clf()
                    plt.close('all')  # conserve memory
                    buffer.seek(0)
                    image = imageio.imread(buffer)
                    writer.append_data(image)

        if save_GIF:
            writer.close()

    print_XST_df_table(df, folder)  # Save the results to Excel
    return


def print_XST_df_table(df, folder):
    """Save a dataframe with XST temperatures to Excel."""
    hash_list = df.index.get_level_values('hash').unique()
    df_list = [df.xs(ha, level='hash') for ha in hash_list]
    for df in df_list:
        df.dropna(axis='columns', how='all', inplace=True)
    path = os.path.join(folder, 'XST.xlsx')
    logger.info('Saving file {}'.format(path))
    trnpy.misc.df_to_excel(df=df_list, path=path, sheet_names=hash_list)


def collect_from_trnpy_dck_list(dck_list, origin, type_=342):
    """Collect results with the TRNpy module."""
    df_list = []
    hash_list = []
    for i, dck in enumerate(dck_list, start=0):
        for result_file in dck.result_files:
            if "Speicher.out" not in result_file:
                # Skip if wrong file type
                continue

            if type_ == 343:
                result_file = result_file.replace('Speicher.out',
                                                  '../fort.343')

            # Construct the full path to the result file
            result_file_path = os.path.join(os.path.dirname(
                                            dck.file_path_dest),
                                            result_file)
            # Use the provided function to read the file
            try:
                if type_ == 342:
                    df_new = read_result_342(result_file_path,
                                             start_date=origin)
                elif type_ == 343:
                    df_new = read_result_343(result_file_path,
                                             start_date=origin)

            except Exception as ex:
                logger.error('Error when trying to read result file "{}":'
                             .format(result_file_path))
                logger.exception(ex)

            # Add the 'hash' and all the key, value pairs to DataFrame
            if dck.hash is not None:
                hash_list.append(dck.hash)
            else:
                hash_list.append(i)

            df_list.append(df_new)

    # Append the old and new df, with a new index.
    df = pd.concat(df_list, keys=hash_list, names=['hash'])
    df.columns.set_names('R-DIST', inplace=True)
    return df
